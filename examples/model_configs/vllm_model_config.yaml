model_parameters:
  model_name: "/llm/intelmc8/models/avoroshilov/DeepSeek-R1-Distill-Qwen-14B-GPTQ_4bit-128g"
  revision: "main"
  load_in_low_bit: "asym_int4"
  quantization: "gptq"
  distributed_executor_backend: "ray"
  dtype: "float16"
  tensor_parallel_size: 4
  data_parallel_size: 1
  pipeline_parallel_size: 1
  gpu_memory_utilization: 0.80
  max_model_length: 8192
  swap_space: 4
  seed: 42
  trust_remote_code: True
  use_chat_template: True
  add_special_tokens: True
  multichoice_continuations_start_space: False
  pairwise_tokenization: False
  subfolder: null
  max_num_seqs: 32
  max_num_batched_tokens: 8192
  generation_parameters:
    presence_penalty: 0.0
    repetition_penalty: 1.0
    frequency_penalty: 0.0
    temperature: 0.3
    top_k: null
    min_p: 0.0
    top_p: 0.9
    seed: 42
    stop_tokens: null
    max_new_tokens: 2048
    min_new_tokens: 0
metrics_options:
  yo: null
